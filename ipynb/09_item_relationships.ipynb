{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 as pg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pandas.algos import nancorr\n",
    "from sys import getsizeof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing item-item relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_cur_to_bgg_db_tuples():\n",
    "    con = pg2.connect(host='34.216.22.202',\n",
    "                  dbname='postgres',\n",
    "                  user='postgres')\n",
    "    cur = con.cursor()\n",
    "    return con, cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sizeof(foo):\n",
    "    return getsizeof(foo) * 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    con, cur = con_cur_to_bgg_db_tuples()\n",
    "    cur.execute('SELECT u.us, g.gs, rating FROM clean_ratings r\\\n",
    "                 INNER JOIN clean_users u\\\n",
    "                 ON r.uid=u.uid\\\n",
    "                 INNER JOIN boardgames g\\\n",
    "                 ON r.gid=g.gid;')\n",
    "    rating_tuples = cur.fetchall()\n",
    "    con.close()\n",
    "    return rating_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_tuples = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.086711224"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizeof(rating_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sparse(tuples, n_users=118632, n_items=10000):\n",
    "    sparse_mat = np.zeros((n_users, n_items))\n",
    "    for row in tuples:\n",
    "        sparse_mat[row[0]-1, row[1]-1] = row[2]\n",
    "    return sparse_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_mat = to_sparse(rating_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/rating_tuples_full', 'rb') as f:\n",
    "    rating_tuples = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.490560112"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizeof(sparse_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_sparsity(sparse_mat):\n",
    "    sparsity = float(len(sparse_mat.nonzero()[0]))\n",
    "    sparsity /= (sparse_mat.shape[0] * sparse_mat.shape[1])\n",
    "    sparsity *= 100\n",
    "    print('Sparsity: {:4.2f}%'.format(sparsity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 0.91%\n"
     ]
    }
   ],
   "source": [
    "calc_sparsity(sparse_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cardinality_set(sparse_mat):\n",
    "    rated = sparse_mat.nonzero()\n",
    "    rated_mat = np.empty_like(sparse_mat)\n",
    "    rated_mat[rated] = 1\n",
    "    card_mat = rated_mat.T.dot(rated_mat)\n",
    "\n",
    "    return card_mat\n",
    "\n",
    "def corr(sparse_mat):\n",
    "    nan_mat = sparse_mat.copy()\n",
    "    nan_mat[nan_mat == 0] = np.nan\n",
    "    corr_mat = nancorr(nan_mat)\n",
    "    corr_mat = np.nan_to_num(corr_mat)\n",
    "\n",
    "    return corr_mat\n",
    "\n",
    "def correct_corr(corr_mat, card_mat, alpha=5):\n",
    "    denom = np.add(card_mat, alpha)\n",
    "    scaling = np.divide(card_mat, denom)\n",
    "    corr_ect = np.multiply(corr_mat, scaling)\n",
    "\n",
    "    return corr_ect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_mat = cardinality_set(sparse_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat = corr(sparse_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/corr_mat_full', 'wb') as f:\n",
    "    pickle.dump(corr_mat, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_ect = correct_corr(corr_mat, card_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/corr_ect_full', 'wb') as f:\n",
    "    pickle.dump(corr_ect, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8000001120000001"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizeof(corr_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_bias_vec(sparse_mat, rated, lam=25):\n",
    "    sum_ratings = np.sum(sparse_mat, axis=0)\n",
    "    _, count = np.unique(rated[1], return_counts=True)\n",
    "    lambda_count = np.add(count, lam)\n",
    "    item_bias = np.divide(sum_ratings, lambda_count)\n",
    "    return item_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_bias = get_item_bias_vec(sparse_mat, rated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/item_bias_vec_full', 'wb') as f:\n",
    "    pickle.dump(item_bias, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing expansions from recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exp():\n",
    "    con, cur = con_cur_to_bgg_db_tuples()\n",
    "    cur.execute('SELECT b.gs, c.gs FROM re_ex a \\\n",
    "                 INNER JOIN boardgames b \\\n",
    "                 ON a.gid=b.gid \\\n",
    "                 INNER JOIN boardgames c \\\n",
    "                 ON a.rx=c.gid;')\n",
    "    exp = cur.fetchall()\n",
    "    con.close()\n",
    "    return exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = get_exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_to_sparse(exp_tuples):\n",
    "    exp_mat = np.zeros([10000, 10000])\n",
    "    for row in exp_tuples:\n",
    "        exp_mat[row[0]-1, row[1]-1] = 1\n",
    "    return exp_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_mat = exp_to_sparse(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/exp_mat_full', 'wb') as f:\n",
    "    pickle.dump(exp_mat, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
